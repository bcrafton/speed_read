
done
-------
> test bench
> slow conv reference (8 rows at a time)
> weight statistic dynamic speed
> variance
> layer-by-layer, bit-by-bit params
> how to hit target variance ? 
> how to make simulations go faster ?
> if pdot == adc:
  > pdot will always be larger
  > so we need to figure out what expected value is, if its larger than 16.
  > then add that much.
  > although expected value might be 16... so wudnt need to add in that case.

> why this so slow ?  
  > https://stackoverflow.com/questions/10789042/python-multi-threading-slower-than-serial
  > apparently python has real issues with this ...
  > multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.
> better performance metric.
  > nmac = (Hi * Wi) * (Fh * Fw * Ci * Co)
  > mwl = (Hi * Wi) * 8 * ((Fh * Fw * Ci) / WL) * (Co / BL)
> collection scripts
> move rpr out of conv
> is pooling necessary ?
  > yes.

future / not doing:
-------
> is there a relationship between the number of rows turned on and the 1s turned on in that row ? 
  store weight density of that row ... or some bit weighted density i.e. 7 more important than 1.

todo
-------
> make sure Ho/Wo and yh/yw are correct.
> ResNet ? 
> BatchNorm
> Intermediate Accuracy #s would also be good.
-------
> run inference, make sure acc is good.
> parse thru code trying to find (nan, 1/0, numerical instability)
-------
> better architecture sim
> device-to-device variance, not read-to-read
> there was 1 more thing ...
> 8 col/adc is good for x/w thing.
  > means we can pick our x/w pretty much however
  > also means we dont have to split at all.
-------

array allocation:
array: 222 cycle: 148 stall: 1548
array: 498 cycle: 381 stall: 52786
array: 240 cycle: 319 stall: 21096
array: 500 cycle: 251 stall: 28416
array: 240 cycle: 269 stall: 17496
array: 432 cycle: 173 stall: 18648

array: 222 cycle: 1280 stall: 22016
array: 498 cycle: 1664 stall: 42240
array: 240 cycle: 1664 stall: 6144
array: 500 cycle: 1408 stall: 48640
array: 240 cycle: 1408 stall: 10240
array: 432 cycle: 1408 stall: 18432

> going to be 2 parts:
1) (layer level) compile time based off of (X, W) statistics
2) (PE level) run time based on when arrays finish

-------





















