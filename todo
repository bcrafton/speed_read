
done
-------
> test bench
> slow conv reference (8 rows at a time)
> weight statistic dynamic speed
> variance
> layer-by-layer, bit-by-bit params
> how to hit target variance ? 
> how to make simulations go faster ?
> if pdot == adc:
  > pdot will always be larger
  > so we need to figure out what expected value is, if its larger than 16.
  > then add that much.
  > although expected value might be 16... so wudnt need to add in that case.

> why this so slow ?  
  > https://stackoverflow.com/questions/10789042/python-multi-threading-slower-than-serial
  > apparently python has real issues with this ...
  > multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.
  
> better performance metric.
  > nmac = (Hi * Wi) * (Fh * Fw * Ci * Co)
  > mwl = (Hi * Wi) * 8 * ((Fh * Fw * Ci) / WL) * (Co / BL)

> collection scripts

> move rpr out of conv

> is pooling necessary ?
  > yes.

future / not doing:
-------
> is there a relationship between the number of rows turned on and the 1s turned on in that row ? 
  store weight density of that row ... or some bit weighted density i.e. 7 more important than 1.

todo
-------
> dynamic profiling
> save {x,y1,y2,...} as tb from tensorflow.
> batchnorm

> bias centering
> cconv cleanup 
> we dont do variance by cell.
  > we do read-to-read variance basically
  > wudnt really be useful for bias centering anyways.
> no skip only go length of x ? 
  > currently it goes whole wl ...

> imagenet64

-------

priority:
> imagenet64

-------

model was wrong -> messed everything up.
> make sure Ho/Wo and yh/yw are correct.

as mean/std of activations/weights goes down, performance skyrockets.

-------

will we be able to support resnet/densenet/mobilenet ? 
> depthwise convolutions are bad for compute in memory.
> pointwise are just fine.

can we find online where state of the art is for 8 bit networks ? 
> what models are people using ? 
> what do accuracy numbers look like ? 

so it seems like everyone respects resnet.
which will be a giant pain to train.

> ResNet ? 
> BatchNorm
> Intermediate Accuracy #s would also be good.
> Parallelize over the 5 GPUs

-------

> run inference, make sure acc is good.
> parse thru code trying to find (nan, 1/0, numerical instability)

-------

> better architecture sim
> device-to-device variance, not read-to-read
> there was 1 more thing ...
> 8col/adc is good for x/w thing.
  > means we can pick our x/w pretty much however
  > also means we dont have to split at all.
  
-------

array allocation:
array: 222 cycle: 148 stall: 1548
array: 498 cycle: 381 stall: 52786
array: 240 cycle: 319 stall: 21096
array: 500 cycle: 251 stall: 28416
array: 240 cycle: 269 stall: 17496
array: 432 cycle: 173 stall: 18648

array: 222 cycle: 1280 stall: 22016
array: 498 cycle: 1664 stall: 42240
array: 240 cycle: 1664 stall: 6144
array: 500 cycle: 1408 stall: 48640
array: 240 cycle: 1408 stall: 10240
array: 432 cycle: 1408 stall: 18432

fix cards:
arrays carry different #s of wb=[1,2,3,4,5,6,7,8] ... which we dont want.
we can allocate redundant arrays based on this.
OR 
we can give each array same # of wb=[...].

problem = we still have 128 ADC per array.
so we cant actually distribute them out properly

-------








